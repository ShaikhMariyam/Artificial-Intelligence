{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMV/QHoiWFJKKq17yGoa44q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["-------\n","# **Assignment 2: Classification Models**\n","## *Shaikh Mariyam Harunor Rashid - A20MJ4010*\n","-------\n","\n","##**Table of Contents**\n","| No. |  | Content       |\n","|---------|----|---------------|\n","| 1.|   | Importing libraries  |\n","| 2.|   | Dataset - Stars|\n","|   |2.1| *Loading the Dataset*|\n","|   |2.2| *Processing the Dataset*|\n","|   |2.3| *Model Training and Evaluation*|\n","|   |2.4| *Model Training and Evaluation*|\n","| 3.|   | Dataset - Mushrooms  |\n","|   |3.1| *Loading the Dataset*|\n","|   |3.2| *Processing the Dataset*|\n","|   |3.3| *Model Training and Evaluation*|\n","|   |3.4| *Model Training and Evaluation*|\n","\n","<br>\n","\n","----"],"metadata":{"id":"CiotPWDxa9ZR"}},{"cell_type":"markdown","source":["# 1. Importing libraries"],"metadata":{"id":"fKQh8F2GbNFu"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"yCcMJ-gxA3af","executionInfo":{"status":"ok","timestamp":1706033313866,"user_tz":-480,"elapsed":1100,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.impute import SimpleImputer\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["The 'star_data' and'mushroom_data' datasets are used to apply different models in the Python code that is given. The script includes all of the important preprocessing procedures for data, including coding categorical features, resolving missing values, normalising numerical attributes, and assessing model performance. It makes use of popular classifiers such as Gradient Boosting, Support Vector Machines (SVM), Decision Trees, Random Forests, K-Nearest Neighbours (KNN), and Logistic Regression. In addition, the code evaluates model accuracy and generates complete classification reports that give a thorough picture of each model's performance on the designated datasets."],"metadata":{"id":"6yJricc2b_uy"}},{"cell_type":"markdown","source":["# 2. Dataset - Stars"],"metadata":{"id":"QMBKMpvZcG18"}},{"cell_type":"markdown","source":["## Loading the Dataset"],"metadata":{"id":"ffwPFU8tdFeI"}},{"cell_type":"code","source":["# Load the dataset\n","star_data = pd.read_csv('/content/Star3642_balanced.csv')\n","star_data.head()\n","imputer = SimpleImputer(strategy='mean')"],"metadata":{"id":"cnfuKxl2REWD","executionInfo":{"status":"ok","timestamp":1706033313867,"user_tz":-480,"elapsed":13,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["To give an overview of the dataset, the code loads the 'Star3642_balanced.csv' dataset using pandas and shows the first few rows. The 'mean' technique is then used to initialise a SimpleImputer, meaning that any missing values in the dataset will be replaced with the mean values of the corresponding columns. In order to ensure consistency and completeness in the dataset and to get it ready for additional analysis and model training, this step is essential."],"metadata":{"id":"U-6dcmujcaex"}},{"cell_type":"markdown","source":["## Processing the Dataset"],"metadata":{"id":"Mzl0BHJ-c7Hu"}},{"cell_type":"code","source":["label_encoders = {}\n","for column in star_data.select_dtypes(include=['object']).columns:\n","    label_encoders[column] = LabelEncoder()\n","    star_data[column] = label_encoders[column].fit_transform(star_data[column])\n","\n","# Splitting the data into features and target\n","X = star_data.drop('TargetClass', axis=1)\n","y = star_data['TargetClass']"],"metadata":{"id":"EygoxnGoRIQy","executionInfo":{"status":"ok","timestamp":1706033313867,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["This code block turns the categorical variables in the 'star_data' dataset into numerical representations by using Label Encoding. After that, the encoded data is divided into the target variable (y) and features (X), readying the dataset for training and assessing machine learning models."],"metadata":{"id":"4gKrY2_2dTys"}},{"cell_type":"code","source":["# Normalizing numerical variables\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Splitting the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","X_train = imputer.fit_transform(X_train)\n","X_test = imputer.transform(X_test)"],"metadata":{"id":"u-UH3-UYUGAI","executionInfo":{"status":"ok","timestamp":1706033313867,"user_tz":-480,"elapsed":11,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["To make sure that the features are on a similar scale, this part of the code uses StandardScaler to normalise the numerical variables. Train_test_split is then used to split the dataset into training and testing sets. 30% of the data are in the testing set (X_test and y_test), while the remaining 70% are in the training set (X_train and y_train). To further prepare the data for model training and assessment, the imputer is also used to handle any remaining missing values."],"metadata":{"id":"DD-I07lzdfcW"}},{"cell_type":"markdown","source":["## Model Training and Evaluation"],"metadata":{"id":"qWMHj1DydqMx"}},{"cell_type":"code","source":["# Dictionary of models for training and evaluation\n","models = {\n","    'LogisticRegression': LogisticRegression(),\n","    'DecisionTreeClassifier': DecisionTreeClassifier(),\n","    'RandomForestClassifier': RandomForestClassifier(),\n","    'SVC': SVC(),\n","    'KNeighborsClassifier': KNeighborsClassifier(),\n","    'GradientBoostingClassifier': GradientBoostingClassifier()\n","}\n","\n","# Dictionary to store accuracy of each model\n","model_accuracies = {}\n","\n","# Training and evaluating each model\n","for name, model in models.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    report = classification_report(y_test, y_pred)\n","    model_accuracies[name] = accuracy\n","    #print(model_accuracies)\n","    #print(report)\n","    print(f\"\\n{'='*40}\\nModel: {name}\\nAccuracy: {accuracy:.4f}\\n{'-'*40}\\nClassification Report:\\n{report}\")\n","    print('='*40)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obRAhIzGRK1p","executionInfo":{"status":"ok","timestamp":1706033315095,"user_tz":-480,"elapsed":1238,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}},"outputId":"e0f188a7-6f03-4567-bf0c-ed4c66a4b91f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========================================\n","Model: LogisticRegression\n","Accuracy: 0.8856\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.89      0.88       540\n","           1       0.89      0.89      0.89       553\n","\n","    accuracy                           0.89      1093\n","   macro avg       0.89      0.89      0.89      1093\n","weighted avg       0.89      0.89      0.89      1093\n","\n","========================================\n","\n","========================================\n","Model: DecisionTreeClassifier\n","Accuracy: 0.8966\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.90      0.90       540\n","           1       0.90      0.89      0.90       553\n","\n","    accuracy                           0.90      1093\n","   macro avg       0.90      0.90      0.90      1093\n","weighted avg       0.90      0.90      0.90      1093\n","\n","========================================\n","\n","========================================\n","Model: RandomForestClassifier\n","Accuracy: 0.9103\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.92      0.91       540\n","           1       0.92      0.90      0.91       553\n","\n","    accuracy                           0.91      1093\n","   macro avg       0.91      0.91      0.91      1093\n","weighted avg       0.91      0.91      0.91      1093\n","\n","========================================\n","\n","========================================\n","Model: SVC\n","Accuracy: 0.8939\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.90      0.89       540\n","           1       0.90      0.89      0.89       553\n","\n","    accuracy                           0.89      1093\n","   macro avg       0.89      0.89      0.89      1093\n","weighted avg       0.89      0.89      0.89      1093\n","\n","========================================\n","\n","========================================\n","Model: KNeighborsClassifier\n","Accuracy: 0.8884\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.89      0.89       540\n","           1       0.90      0.88      0.89       553\n","\n","    accuracy                           0.89      1093\n","   macro avg       0.89      0.89      0.89      1093\n","weighted avg       0.89      0.89      0.89      1093\n","\n","========================================\n","\n","========================================\n","Model: GradientBoostingClassifier\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.92      0.91       540\n","           1       0.92      0.91      0.91       553\n","\n","    accuracy                           0.91      1093\n","   macro avg       0.91      0.91      0.91      1093\n","weighted avg       0.91      0.91      0.91      1093\n","\n","========================================\n"]}]},{"cell_type":"markdown","source":["This part creates a dictionary called models that contains several machine learning classifiers, including K-Neighbors, Gradient Boosting, Support Vector Classifier (SVC), Decision Tree, Random Forest, and Logistic Regression. After that, the algorithm goes over each model iteratively, trains it on the X_train and y_train training sets, and assesses its performance on the X_test and y_test testing sets. Every model's accuracy is recorded in the model_accuracies dictionary, and comprehensive reports on categorization are generated, offering valuable perspectives into the predictive powers of the models."],"metadata":{"id":"aftyuzLJd5HM"}},{"cell_type":"markdown","source":["## Summary and Conclusion\n","\n","- The models exhibit competitive performance, with the Gradient Boosting Classifier outperforming others with the highest accuracy of 91.13%.\n","- All models showcase balanced precision, recall, and F1-score, indicating their effectiveness across both classes.\n","- The Decision Tree, Random Forest, and Gradient Boosting models stand out as strong candidates for this classification task.\n","- Further hyperparameter tuning and optimization could potentially enhance the models' performance.\n"],"metadata":{"id":"X9Gcm-1Df7hH"}},{"cell_type":"markdown","source":["# 3. Dataset - Mushrooms"],"metadata":{"id":"sCf7tVyteTXt"}},{"cell_type":"markdown","source":["## Loading the Dataset"],"metadata":{"id":"pMD4XX7neaz2"}},{"cell_type":"code","source":["mushroom_data = pd.read_csv('/content/mushrooms.csv')\n","mushroom_data.head()\n","imputer = SimpleImputer(strategy='mean')"],"metadata":{"id":"E5OCHSuYaAJ6","executionInfo":{"status":"ok","timestamp":1706033315096,"user_tz":-480,"elapsed":10,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["This section of the code begins by loading the 'mushrooms.csv' dataset using pandas (pd.read_csv). The head() function is then used to display the first few rows of the dataset, offering a preliminary look at its structure. Following this, a SimpleImputer is initialized with the strategy of replacing missing values with the mean, preparing the data for subsequent preprocessing steps."],"metadata":{"id":"hciKvUV5esPw"}},{"cell_type":"markdown","source":["## Processing the Dataset"],"metadata":{"id":"8aac3stWefDI"}},{"cell_type":"code","source":["label_encoders = {}\n","for column in mushroom_data.select_dtypes(include=['object']).columns:\n","    label_encoders[column] = LabelEncoder()\n","    mushroom_data[column] = label_encoders[column].fit_transform(mushroom_data[column])\n","\n","# Splitting the data into features and target\n","X = mushroom_data.drop('class', axis=1)\n","y = mushroom_data['class']"],"metadata":{"id":"2uq9DWRBaAVq","executionInfo":{"status":"ok","timestamp":1706033315096,"user_tz":-480,"elapsed":9,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["In this section, Label Encoding is used to encode categorical variables in the 'mushroom_data' dataset. Instances of the LabelEncoder for every category column are kept in a dictionary called label_encoders. The code converts categorical values into numerical representations by iterating over object-type columns.\n","\n","The dataset is then divided into the target variable (y) and characteristics (X). The target variable (y) is given the values from the 'class' column, and features (X) are derived by removing the 'class' column. The data is made ready for machine learning model training and assessment by this encoding and splitting process."],"metadata":{"id":"gGkyuah4fEI8"}},{"cell_type":"code","source":["# Normalizing numerical variables\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Splitting the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","X_train = imputer.fit_transform(X_train)\n","X_test = imputer.transform(X_test)"],"metadata":{"id":"1s5OX2lzaAdv","executionInfo":{"status":"ok","timestamp":1706033315096,"user_tz":-480,"elapsed":8,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["In this part of the code, StandardScaler is used to normalise the numerical variables in the dataset (X). By ensuring that the features are on a consistent scale, this step helps to improve the effectiveness of model training.\n","\n","The dataset is then divided using train_test_split into training and testing sets (X_train, X_test, y_train, y_test). 30% of the data is from the testing set, and 70% is from the training set. Furthermore, the previously initialised imputer is used to handle missing values in the training and testing sets. In order to prepare the data for machine learning model training and subsequent evaluation, several preprocessing processes are essential."],"metadata":{"id":"wJLtnIgafXjM"}},{"cell_type":"markdown","source":["## Model Training and Evaluation"],"metadata":{"id":"tsoJ3A15ei_A"}},{"cell_type":"code","source":["# Dictionary of models for training and evaluation\n","models2 = {\n","    'LogisticRegression': LogisticRegression(),\n","    'DecisionTreeClassifier': DecisionTreeClassifier(),\n","    'RandomForestClassifier': RandomForestClassifier(),\n","    'SVC': SVC(),\n","    'KNeighborsClassifier': KNeighborsClassifier(),\n","    'GradientBoostingClassifier': GradientBoostingClassifier()\n","}\n","\n","# Dictionary to store accuracy of each model\n","model_accuracies2 = {}\n","\n","# Training and evaluating each model\n","for name, model in models2.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    accuracy2 = accuracy_score(y_test, y_pred)\n","    report2 = classification_report(y_test, y_pred)\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        report = classification_report(y_test, y_pred, zero_division=1)\n","    model_accuracies2[name] = accuracy2\n","    print(f\"\\n{'='*40}\\nModel: {name}\\nAccuracy: {accuracy:.4f}\\n{'-'*40}\\nClassification Report:\\n{report}\")\n","    print('='*40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qsksnJvaAmJ","executionInfo":{"status":"ok","timestamp":1706033317355,"user_tz":-480,"elapsed":2266,"user":{"displayName":"Shaikh Mariyam","userId":"05207327436429082971"}},"outputId":"c4c6f630-f0e1-4484-c475-b396440c042c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========================================\n","Model: LogisticRegression\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.95      0.95      1257\n","           1       0.95      0.95      0.95      1181\n","\n","    accuracy                           0.95      2438\n","   macro avg       0.95      0.95      0.95      2438\n","weighted avg       0.95      0.95      0.95      2438\n","\n","========================================\n","\n","========================================\n","Model: DecisionTreeClassifier\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1257\n","           1       1.00      1.00      1.00      1181\n","\n","    accuracy                           1.00      2438\n","   macro avg       1.00      1.00      1.00      2438\n","weighted avg       1.00      1.00      1.00      2438\n","\n","========================================\n","\n","========================================\n","Model: RandomForestClassifier\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1257\n","           1       1.00      1.00      1.00      1181\n","\n","    accuracy                           1.00      2438\n","   macro avg       1.00      1.00      1.00      2438\n","weighted avg       1.00      1.00      1.00      2438\n","\n","========================================\n","\n","========================================\n","Model: SVC\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1257\n","           1       1.00      1.00      1.00      1181\n","\n","    accuracy                           1.00      2438\n","   macro avg       1.00      1.00      1.00      2438\n","weighted avg       1.00      1.00      1.00      2438\n","\n","========================================\n","\n","========================================\n","Model: KNeighborsClassifier\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1257\n","           1       1.00      1.00      1.00      1181\n","\n","    accuracy                           1.00      2438\n","   macro avg       1.00      1.00      1.00      2438\n","weighted avg       1.00      1.00      1.00      2438\n","\n","========================================\n","\n","========================================\n","Model: GradientBoostingClassifier\n","Accuracy: 0.9113\n","----------------------------------------\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1257\n","           1       1.00      1.00      1.00      1181\n","\n","    accuracy                           1.00      2438\n","   macro avg       1.00      1.00      1.00      2438\n","weighted avg       1.00      1.00      1.00      2438\n","\n","========================================\n"]}]},{"cell_type":"markdown","source":["A new set of machine learning models (models2) is introduced in this section of the code for evaluation and training on an alternative dataset. Among the models are the following: K-Neighbors, Gradient Boosting, Support Vector Classifier (SVC), Random Forest, Decision Tree, and Logistic Regression.\n","\n","The algorithm predicts on the testing set (X_test), fits each model to the training set (X_train and y_train), and then iterates through each model, assessing its performance. Each model's accuracy is recorded in the model_accuracies2 dictionary, and comprehensive reports on classification are generated that offer valuable information about each model's predictive power on the second dataset. The code also addresses any division mistakes in the classification report."],"metadata":{"id":"LEqL3Ml6fpQL"}},{"cell_type":"markdown","source":["## Summary and Conclusion\n","- All models exhibit remarkable accuracy and performance on the mushroom dataset, achieving perfect metrics for both classes.\n","- The Decision Tree, Random Forest, SVC, K-Neighbors, and Gradient Boosting models showcase identical accuracy, precision, recall, and F1-score, indicating potential overfitting or an issue with the dataset.\n","- Further investigation into dataset characteristics, potential class imbalances, or the need for additional features is recommended to address the observed high performance and potential overfitting.\n"],"metadata":{"id":"rtgslAuJgxpr"}}]}